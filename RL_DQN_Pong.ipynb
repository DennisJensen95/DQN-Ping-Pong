{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning applied to an Atari Pong game\n",
    "\n",
    "By Dennis Jensen s155629 & Stefan Carius Larsen s164029\n",
    "\n",
    "This notebook displays and shows results of the implemented Deep Q-Networks applied to the atari game pong.\n",
    "Throughout the project three different models were applied and trained on the pong game. Each model implements a neural network which consists of a convolutional network with three layers and two dense layers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With opengym.ai an atari pong game setup is supplied with a reward system. With the gym module you have an agent playing against a standard computer playing. The agent gets rewarded if it wins a round and gets penalized if it looses a round. One win gives +1 and a lost gives -1. \n",
    "\n",
    "<img src=\"pong_rgb.png\">\n",
    "\n",
    "## Scaling image, Grayscale image and Skipping Frames\n",
    "For scaling, grayscaling and skipping frames the OpenAi Gym Wrappers are used.\n",
    "\n",
    "### OpenAi Gym Wrappers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import collections\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from OpenAI baseline wrappers\n",
    "# https://github.com/openai/baselines/blob/master/baselines/common/atari_wrappers.py\n",
    "\n",
    "class FireResetEnv(gym.Wrapper):\n",
    "    def __init__(self, env=None):\n",
    "        \"\"\"Take action on reset for environments that are fixed until firing.\"\"\"\n",
    "        super(FireResetEnv, self).__init__(env)\n",
    "        print(env.unwrapped.get_action_meanings())\n",
    "        assert env.unwrapped.get_action_meanings()[1] == 'FIRE'\n",
    "        assert len(env.unwrapped.get_action_meanings()) >= 3\n",
    "\n",
    "    def step(self, action):\n",
    "        return self.env.step(action)\n",
    "\n",
    "    def reset(self):\n",
    "        self.env.reset()\n",
    "        obs, _, done, _ = self.env.step(1)\n",
    "        if done:\n",
    "            self.env.reset()\n",
    "        obs, _, done, _ = self.env.step(2)\n",
    "        if done:\n",
    "            self.env.reset()\n",
    "        return obs\n",
    "\n",
    "\n",
    "class MaxAndSkipEnv(gym.Wrapper):\n",
    "    def __init__(self, env=None, skip=4):\n",
    "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
    "        super(MaxAndSkipEnv, self).__init__(env)\n",
    "        # most recent raw observations (for max pooling across time steps)\n",
    "        self._obs_buffer = collections.deque(maxlen=2)\n",
    "        self._skip = skip\n",
    "\n",
    "    def step(self, action):\n",
    "        total_reward = 0.0\n",
    "        done = None\n",
    "        for _ in range(self._skip):\n",
    "            obs, reward, done, info = self.env.step(action)\n",
    "            self._obs_buffer.append(obs)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        max_frame = np.max(np.stack(self._obs_buffer), axis=0)\n",
    "        return max_frame, total_reward, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Clear past frame buffer and init to first obs\"\"\"\n",
    "        self._obs_buffer.clear()\n",
    "        obs = self.env.reset()\n",
    "        self._obs_buffer.append(obs)\n",
    "        return obs\n",
    "\n",
    "\n",
    "class ProcessFrame84(gym.ObservationWrapper):\n",
    "    \"\"\"\n",
    "    Downsamples image to 84x84\n",
    "    Greyscales image\n",
    "\n",
    "    Returns numpy array\n",
    "    \"\"\"\n",
    "    def __init__(self, env=None):\n",
    "        super(ProcessFrame84, self).__init__(env)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=(84, 84, 1), dtype=np.uint8)\n",
    "\n",
    "    def observation(self, obs):\n",
    "        return ProcessFrame84.process(obs)\n",
    "\n",
    "    @staticmethod\n",
    "    def process(frame):\n",
    "        if frame.size == 210 * 160 * 3:\n",
    "            img = np.reshape(frame, [210, 160, 3]).astype(np.float32)\n",
    "        elif frame.size == 250 * 160 * 3:\n",
    "            img = np.reshape(frame, [250, 160, 3]).astype(np.float32)\n",
    "        else:\n",
    "            assert False, \"Unknown resolution.\"\n",
    "        img = img[:, :, 0] * 0.299 + img[:, :, 1] * 0.587 + img[:, :, 2] * 0.114\n",
    "        resized_screen = cv2.resize(img, (84, 110), interpolation=cv2.INTER_AREA)\n",
    "        x_t = resized_screen[18:102, :]\n",
    "        x_t = np.reshape(x_t, [84, 84, 1])\n",
    "        return x_t.astype(np.uint8)\n",
    "\n",
    "\n",
    "class ImageToPyTorch(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super(ImageToPyTorch, self).__init__(env)\n",
    "        old_shape = self.observation_space.shape\n",
    "        self.observation_space = gym.spaces.Box(low=0.0, high=1.0, shape=(old_shape[-1], old_shape[0], old_shape[1]),\n",
    "                                                dtype=np.float32)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        return np.moveaxis(observation, 2, 0)\n",
    "\n",
    "\n",
    "class ScaledFloatFrame(gym.ObservationWrapper):\n",
    "    \"\"\"Normalize pixel values in frame --> 0 to 1\"\"\"\n",
    "    def observation(self, obs):\n",
    "        return np.array(obs).astype(np.float32) / 255.0\n",
    "\n",
    "\n",
    "class BufferWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env, n_steps, dtype=np.float32):\n",
    "        super(BufferWrapper, self).__init__(env)\n",
    "        self.dtype = dtype\n",
    "        old_space = env.observation_space\n",
    "        self.observation_space = gym.spaces.Box(old_space.low.repeat(n_steps, axis=0),\n",
    "                                                old_space.high.repeat(n_steps, axis=0), dtype=dtype)\n",
    "\n",
    "    def reset(self):\n",
    "        self.buffer = np.zeros_like(self.observation_space.low, dtype=self.dtype)\n",
    "        return self.observation(self.env.reset())\n",
    "\n",
    "    def observation(self, observation):\n",
    "        self.buffer[:-1] = self.buffer[1:]\n",
    "        self.buffer[-1] = observation\n",
    "        return self.buffer\n",
    "\n",
    "\n",
    "def make_env(env_name):\n",
    "    env = gym.make(env_name)\n",
    "    env = MaxAndSkipEnv(env)\n",
    "    env = FireResetEnv(env)\n",
    "    env = ProcessFrame84(env)\n",
    "    env = ImageToPyTorch(env)\n",
    "    env = BufferWrapper(env, 4)\n",
    "    return ScaledFloatFrame(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The architechture of the DQN, DDQN, CDDQN\n",
    "\n",
    "Our Deep-Q-Network is made up of:\n",
    "\n",
    "3 convolution layers\n",
    "2 dense (fully connected) layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_shape, n_actions, learning_rate):\n",
    "        super(DQN, self).__init__()\n",
    "\n",
    "        channels = input_shape[0]\n",
    "\n",
    "        # First conv layer\n",
    "        conv_out_channels = 32  # <-- Filters in your convolutional layer\n",
    "        kernel_size = 8  # <-- Kernel size\n",
    "        conv_stride = 4  # <-- Stride\n",
    "        conv_pad = 0  # <-- Padding\n",
    "\n",
    "        # Second conv layer\n",
    "        conv_out_channels_2 = 64  # <-- Filters in your convolutional layer\n",
    "        kernel_size_2 = 4  # <-- Kernel size\n",
    "        conv_stride_2 = 2  # <-- Stride\n",
    "        conv_pad_2 = 0  # <-- Padding\n",
    "\n",
    "        # Third conv layer\n",
    "        conv_out_channels_3 = 64  # <-- Filters in your convolutional layer\n",
    "        kernel_size_3 = 3  # <-- Kernel size\n",
    "        conv_stride_3 = 1  # <-- Stride\n",
    "        conv_pad_3 = 0  # <-- Padding\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(channels, conv_out_channels, kernel_size, conv_stride, conv_pad),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(conv_out_channels, conv_out_channels_2, kernel_size_2, conv_stride_2, conv_pad_2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(conv_out_channels_3, conv_out_channels_3, kernel_size_3, conv_stride_3, conv_pad_3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "\n",
    "        out_features = self.conv_out_features(input_shape)\n",
    "\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(out_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, n_actions)\n",
    "        )\n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        return self.out(x)\n",
    "\n",
    "    def conv_out_features(self, shape):\n",
    "        o = self.conv(torch.zeros(1, *shape))\n",
    "        return int(np.prod(o.size()))\n",
    "\n",
    "\n",
    "    def calculate_loss(self, batch, net, target_net, GAMMA, model, device=\"cpu\"):\n",
    "        \"\"\"\n",
    "        This calculate loss function computes loss in three different ways depending on model chosen.\n",
    "        DQN - One network computing next state and current state\n",
    "        DDQN - Target network computing next state and training network computing current state\n",
    "        CDDQN - Seperate networks computes both next state and current state and then loss is computed from the\n",
    "        minimum of the two next states\n",
    "        \"\"\"\n",
    "        states, actions, rewards, dones, next_states = batch\n",
    "\n",
    "        states_v = torch.tensor(states).to(device)\n",
    "        next_states_v = torch.tensor(next_states).to(device)\n",
    "        actions_v = torch.tensor(actions).to(device)\n",
    "        rewards_v = torch.tensor(rewards).to(device)\n",
    "        done = torch.tensor(dones).to(device)\n",
    "\n",
    "        if model == 'DQN' or model == 'DDQN':\n",
    "            if model == 'DQN':\n",
    "                state_action_values = net(states_v).gather(1, actions_v.long().unsqueeze(-1)).squeeze(-1)\n",
    "                next_state_values = net(next_states_v).max(1)[0]\n",
    "            elif model == 'DDQN':\n",
    "                state_action_values = net(states_v).gather(1, actions_v.long().unsqueeze(-1)).squeeze(-1)\n",
    "                next_state_values = target_net(next_states_v).max(1)[0]\n",
    "\n",
    "            next_state_values[done] = 0.0\n",
    "            next_state_values = next_state_values.detach()\n",
    "\n",
    "            expected_state_action_values = next_state_values * GAMMA + rewards_v\n",
    "\n",
    "            return nn.MSELoss()(state_action_values, expected_state_action_values)\n",
    "\n",
    "        elif model == 'CDDQN':\n",
    "            state_Q1 = net(states_v).gather(1, actions_v.long().unsqueeze(-1)).squeeze(-1)\n",
    "            state_Q2 = target_net(states_v).gather(1, actions_v.long().unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "            next_Q1 = net(next_states_v).max(1)[0]\n",
    "            next_Q2 = target_net(next_states_v).max(1)[0]\n",
    "            # print(next_Q2)\n",
    "            next_Q = torch.min(\n",
    "                next_Q1,\n",
    "                next_Q2\n",
    "            )\n",
    "\n",
    "            # next_Q = next_Q.view(next_Q.size(0), 1)\n",
    "            next_Q[done] = 0.0\n",
    "            next_Q = next_Q.detach()\n",
    "\n",
    "            expected_Q = rewards_v + GAMMA * next_Q\n",
    "            # expected_Q = expected_Q.detach()\n",
    "\n",
    "            loss_1 = nn.MSELoss()(state_Q1, expected_Q)\n",
    "            loss_2 = nn.MSELoss()(state_Q2, expected_Q)\n",
    "\n",
    "            return loss_1, loss_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Class for Experience Replay\n",
    "\n",
    "The memory is for being able to learn from uncorrelated data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = collections.namedtuple('Transition', ('state', 'action', 'reward', 'done', 'new_state'))\n",
    "\n",
    "class Memory():\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = []\n",
    "        self.capacity = capacity\n",
    "        self.position = 0\n",
    "\n",
    "    def save_to_memory(self, *args):\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append(None)\n",
    "        self.buffer[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        indices = np.random.choice(len(self.buffer), batch_size, replace=False)\n",
    "        states, actions, rewards, dones, next_states = zip(*[self.buffer[idx] for idx in indices])\n",
    "\n",
    "        return np.array(states), np.array(actions), np.array(rewards, dtype=np.float32), \\\n",
    "               np.array(dones, dtype=np.bool), np.array(next_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Class \n",
    "\n",
    "The agent class is for playing the game and saving the plays to the memory to learn from it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, env, memory):\n",
    "        self.env = env\n",
    "        self.memory = memory\n",
    "        self.env_state = None\n",
    "        self.env_set = False\n",
    "\n",
    "    def reset_environtment(self):\n",
    "        self.env_state = self.env.reset()\n",
    "        self.env_set = True\n",
    "        self.total_reward = 0.0\n",
    "\n",
    "    def random_epsilon_greedy(self, network, device):\n",
    "        assert (self.env_set), \"Please initialize game before playing by resetting or inputting a state\"\n",
    "        state = np.array([self.env_state], copy=False)\n",
    "        state = torch.tensor(state).to(device)\n",
    "        q_values = network(state)\n",
    "        _, pref_action = torch.max(q_values, dim=1)\n",
    "        action = int(pref_action.item())\n",
    "        return action\n",
    "\n",
    "    def play_action(self, network, e=0, device='cpu'):\n",
    "        done_reward = None\n",
    "        if np.random.random() < e:\n",
    "            action = self.env.action_space.sample()\n",
    "        else:\n",
    "            action = self.random_epsilon_greedy(network, device)\n",
    "\n",
    "        # Do action in the environment\n",
    "        new_state, reward, done, _ = self.env.step(action)\n",
    "        self.total_reward += reward\n",
    "        old_state = self.env_state\n",
    "        self.env_state = new_state\n",
    "\n",
    "        self.memory.save_to_memory(old_state, action, reward, done, self.env_state)\n",
    "\n",
    "        if done:\n",
    "            done_reward = self.total_reward\n",
    "            self.reset_environtment()\n",
    "\n",
    "        return done_reward\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the models\n",
    "\n",
    "Depending on the model, there is a different approach for updaing and training the model. All these are implemented in the following functions.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the training loop has been inspired by https://colab.research.google.com/drive/1NsbSPn6jOcaJB_mp9TmkgQX7UrRIrTi0\n",
    "\n",
    "def name_new(file, num=0):\n",
    "    if os.path.exists(file) and num==0:\n",
    "        return name_new(file + f'_{num+1}', num+1)\n",
    "    else:\n",
    "        if os.path.exists(file):\n",
    "            # print(\"Here?\")\n",
    "            remove_str = re.findall(f'_\\d+', file)[0]\n",
    "            # print(remove_str)\n",
    "            new_name = file.replace(remove_str, '') + f'_{num+1}'\n",
    "            return name_new(new_name, num+1)\n",
    "        else:\n",
    "            # print(file)\n",
    "            return file\n",
    "\n",
    "def update(batch_size, memory, net, target_net, gamma, model, device):\n",
    "    if model == 'DDQN' or model == 'DQN':\n",
    "        net.optimizer.zero_grad()\n",
    "        batch = memory.sample(batch_size)\n",
    "        loss_t = net.calculate_loss(batch, net, target_net, gamma, model, device)\n",
    "        loss_t.backward()\n",
    "        net.optimizer.step()\n",
    "    elif model == 'CDDQN':\n",
    "        batch = memory.sample(batch_size)\n",
    "        loss_1, loss_2 = net.calculate_loss(batch, net, target_net, gamma, model, device)\n",
    "\n",
    "        net.optimizer.zero_grad()\n",
    "        loss_1.backward()\n",
    "        net.optimizer.step()\n",
    "\n",
    "        target_net.optimizer.zero_grad()\n",
    "        loss_2.backward()\n",
    "        target_net.optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "def train(env, net, target_net, epsilon_data, agent, memory, gamma, device,\n",
    "          LEARNING_STARTS, TARGET_UPDATE_FREQ, batch_size, model):\n",
    "    # main loop\n",
    "    frame_num = 0\n",
    "    prev_input = None\n",
    "\n",
    "    # initialization of variables used in the main loop\n",
    "    reward_sum = 0\n",
    "    total_rewards = []\n",
    "    start = time.time()\n",
    "    timestep_frame = 0\n",
    "    best_mean_reward = None\n",
    "    mean_reward_bound = 20.5\n",
    "    freq_saving_reward = 1000\n",
    "    save_reward = False\n",
    "    # print(os.getcwd())\n",
    "    filename = './data/frames_reward'\n",
    "    file_name = name_new(filename)\n",
    "    # print(file_name)\n",
    "    name_to_save = model\n",
    "\n",
    "    while True:\n",
    "        frame_num += 1\n",
    "        epsilon = max(epsilon_data[0], epsilon_data[1] - frame_num / epsilon_data[2])\n",
    "\n",
    "        reward = agent.play_action(net, epsilon, device)\n",
    "\n",
    "        if frame_num & freq_saving_reward == 0:\n",
    "            save_reward = True\n",
    "\n",
    "        if reward is not None:\n",
    "            total_rewards.append(reward)\n",
    "            speed = (frame_num - timestep_frame) / (time.time() - start)\n",
    "            timestep_frame = frame_num\n",
    "            start = time.time()\n",
    "            mean_reward = np.mean(total_rewards[-100:])\n",
    "            print(\"{} frames: done {} games, mean reward {}, eps {}, speed {} f/s\".format(\n",
    "                frame_num, len(total_rewards), round(mean_reward, 3), round(epsilon, 2), round(speed, 2)))\n",
    "\n",
    "            if best_mean_reward is None or best_mean_reward < mean_reward:\n",
    "                torch.save(net.state_dict(), f'./data/{name_to_save}_10_6' + \"-\" + str(len(total_rewards)) + \".dat\")\n",
    "                if best_mean_reward is not None:\n",
    "                    print(\"New best mean reward {} -> {}, model saved\".format(round(best_mean_reward, 3),\n",
    "                                                                              round(mean_reward, 3)))\n",
    "                best_mean_reward = mean_reward\n",
    "\n",
    "            if mean_reward > mean_reward_bound and len(total_rewards) > 10:\n",
    "                print(\"Game solved in {} frames! Average score of {}\".format(frame_num, mean_reward))\n",
    "                break\n",
    "\n",
    "            if save_reward:\n",
    "                with open(file_name, 'a') as file:\n",
    "                    file.write(f'{frame_num}:{round(mean_reward, 2)}:{round(epsilon, 2)}\\n')\n",
    "\n",
    "                save_reward = False\n",
    "\n",
    "        if len(memory.buffer) < LEARNING_STARTS:\n",
    "            continue\n",
    "\n",
    "        if frame_num % TARGET_UPDATE_FREQ == 0 and model == 'DDQN':\n",
    "            target_net.load_state_dict(net.state_dict())\n",
    "\n",
    "        # Update depending on model\n",
    "        update(batch_size, memory, net, target_net, gamma, model, device)\n",
    "\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Parameters & Other Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epsilon greedy parameters\n",
    "EPSILON_DECAY = 10**5\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_FINAL = 0.02\n",
    "epsilon_data = [EPSILON_FINAL, EPSILON_START, EPSILON_DECAY]\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 1e-4\n",
    "REPLAY_SIZE = 100000\n",
    "BATCH_SIZE = 32\n",
    "TARGET_UPDATE_FREQ = 1000\n",
    "DELAY_LEARNING = 50000\n",
    "GAMMA = 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiating training, random play or playing pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']\n",
      "The GPU is being used\n"
     ]
    }
   ],
   "source": [
    "UP_ACTION = 2\n",
    "DOWN_ACTION = 3\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# This options dict was created from sys.argv[x] normally, but in ipynb this is redundant, hence a dictionary is made here.\n",
    "option_dict = {'random': False, 'train': False, 'oldnetwork': False} # Change dictionary values for decision making.\n",
    "model = 'DDQN' # Either DQN, DDQN or CDDQN\n",
    "\n",
    "# Environment and neural networks\n",
    "env = make_env('PongNoFrameskip-v4')\n",
    "net = DQN(env.observation_space.shape, env.action_space.n, learning_rate).to(device)\n",
    "target_net = DQN(env.observation_space.shape, env.action_space.n, learning_rate).to(device)\n",
    "\n",
    "# Agent and memory handling\n",
    "memory = Memory(REPLAY_SIZE)\n",
    "agent = Agent(env, memory)\n",
    "\n",
    "initial_observation = env.reset()\n",
    "\n",
    "\n",
    "\n",
    "if 'cuda' in str(device):\n",
    "    print('The GPU is being used')\n",
    "else:\n",
    "    print('The CPU is being used')\n",
    "\n",
    "if option_dict['random']:\n",
    "    play_random(env, UP_ACTION, DOWN_ACTION, seconds=5)\n",
    "\n",
    "if option_dict['train']:\n",
    "    print(\"Training\")\n",
    "    print(\"ReplayMemory will require {}gb of GPU RAM\".format(round(REPLAY_SIZE * 32 * 84 * 84 / 1e+9, 2)))\n",
    "    agent.reset_environtment()\n",
    "    train(env, net, target_net, epsilon_data, agent, memory, GAMMA, device,\n",
    "                DELAY_LEARNING, TARGET_UPDATE_FREQ, BATCH_SIZE, model)\n",
    "\n",
    "if option_dict['oldnetwork']:\n",
    "    file_path = './pull/Best_performing_model/DDQN_10_6-reward_7.97.dat'\n",
    "    seconds = 30\n",
    "    test_old_network(env, net, file_path, seconds, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After all three models have been trained displaying results is:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "\n",
    "\n",
    "def get_data(filename):\n",
    "    x = []\n",
    "    y = []\n",
    "    e = []\n",
    "    file = open(filename, 'r+')\n",
    "    data = file.read()\n",
    "    file.close()\n",
    "    lines = data.split('\\n')\n",
    "\n",
    "    for line in lines:\n",
    "        data_point = re.findall('(-?[\\d.]+)', line)\n",
    "        # print(data_point)\n",
    "        if len(data_point) > 2:\n",
    "            x_result, y_result, e_result = data_point[0], data_point[1], data_point[2]\n",
    "            x.append(x_result)\n",
    "            y.append(y_result)\n",
    "            e.append(e_result)\n",
    "        elif len(data_point) > 1:\n",
    "            x_result, y_result = data_point[0], data_point[1]\n",
    "            x.append(x_result)\n",
    "            y.append(y_result)\n",
    "\n",
    "    x = np.array(x).astype(np.float)\n",
    "    y = np.array(y).astype(np.float)\n",
    "    e = np.array(e).astype(np.float)\n",
    "    return x, y, e\n",
    "\n",
    "def plot_one():\n",
    "    path = './../pull/data/frames_reward_8'\n",
    "    # path = './../data/frames_reward.dat'\n",
    "    frame, reward, e = get_data(path)\n",
    "    frame = frame[1:]\n",
    "    # print(max(reward))\n",
    "    reward = reward[1:]\n",
    "    e = e[1:]\n",
    "    plt.figure()\n",
    "    plt.plot(frame, reward)\n",
    "    plt.ylabel('Reward')\n",
    "    plt.xlabel('Number of frames')\n",
    "    if len(e) > 1:\n",
    "        plt.figure()\n",
    "        plt.plot(frame, e)\n",
    "        plt.xlabel('Number of frames')\n",
    "        plt.ylabel('Epsilon')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def millions(x, pos):\n",
    "    'The two args are the value and tick position'\n",
    "    return '%1.1fM' % (x * 1e-6)\n",
    "\n",
    "def plot_epsilon():\n",
    "    DDQN_path = './pull/Best_performing_model/DDQN/DDQN_frames_reward'\n",
    "\n",
    "    x, y, e = get_data(DDQN_path)\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    e = e[:200]\n",
    "    x = x[:200]\n",
    "    plt.plot(x, e)\n",
    "    plt.xlabel('Number of frames')\n",
    "    plt.ylabel('Epsilon value')\n",
    "    # formatter = ticker.FuncFormatter(millions)\n",
    "    # ax.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_multiple():\n",
    "    \"\"\"\"\"\"\n",
    "    DDQN_path = './pull/pong_v4_data/DQN_reward'\n",
    "    DQN_path = './pull/pong_v4_data/DDQN_reward'\n",
    "    CDQN_path = './pull/pong_v4_data/CDDQN_reward'\n",
    "    \n",
    "    paths = [DQN_path, DDQN_path, CDQN_path]\n",
    "    \n",
    "    i = 0\n",
    "    max_frame = 0\n",
    "    min_frame = 0\n",
    "    for file in paths:\n",
    "        frame, reward, e = get_data(file)\n",
    "        frame = frame[1:]\n",
    "        reward = reward[1:]\n",
    "        if max(frame) > max_frame:\n",
    "            max_frame = max(frame)\n",
    "        if min(frame) < min_frame:\n",
    "            min_frame = min(frame)\n",
    "\n",
    "        #print(max_frame/len(frame))\n",
    "\n",
    "        #print(f'{max(reward)}')\n",
    "\n",
    "        if i == 0:\n",
    "            fig, ax = plt.subplots()\n",
    "        x = []\n",
    "        # frame = millions(frame)\n",
    "        plt.plot(frame, reward)\n",
    "        plt.ylabel('Reward')\n",
    "        plt.xlabel('Number of frames')\n",
    "        i += 1\n",
    "\n",
    "    plt.hlines(-3, min_frame, max_frame)\n",
    "    formatter = ticker.FuncFormatter(millions)\n",
    "\n",
    "    plt.legend(['DQN', 'Double DQN', 'Clipped Double DQN', 'Average Human Performance'])\n",
    "    ax.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    plot_multiple()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
